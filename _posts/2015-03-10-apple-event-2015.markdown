from gensim import corpora, models, similarities  
  
# 创建语料库  
doc1 = "This is the first document."  
doc2 = "This is the second second document."  
doc3 = "And the third one."  
corpus = [doc1, doc2, doc3]  
  
# 对语料库进行分词和词形还原  
texts = [[text for text in doc.split()] for doc in corpus]  
  
# 创建字典和语料库  
dictionary = corpora.Dictionary(texts)  
corpus = [dictionary.doc2bow(text) for text in texts]  
  
# 使用TF-IDF模型转换语料库  
tfidf = models.TfidfModel(corpus)  
corpus_tfidf = tfidf[corpus]  
  
# 使用LSI模型转换语料库  
lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=2)  
corpus_lsi = lsi[corpus_tfidf]  
  
# 计算文本之间的相似度  
index = similarities.MatrixSimilarity(corpus_lsi)  
sims = index[corpus_lsi]  
print(sims)
